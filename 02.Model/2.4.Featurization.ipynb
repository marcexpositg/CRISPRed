{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.4.Featurization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOg2UM1rpg7Qolq+Tvrik5t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcexpositg/CRISPRed/blob/master/02.Model/2.4.Featurization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7i2K26HixhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from Bio import SeqIO\n",
        "from math import exp\n",
        "from re import findall\n",
        "from Bio.SeqUtils import MeltingTemp as mt\n",
        "import csv\n",
        "from itertools import product\n",
        "\n",
        "def read_target_seqs(target_seqs_file):\n",
        "    col_names = [\"gRNA_id\", \"target_seq\"]\n",
        "    target_seqs = pd.read_csv(target_seqs_file, names = col_names)\n",
        "    return target_seqs\n",
        "\n",
        "#############\n",
        "## Strategy inespecific sequence features\n",
        "#############\n",
        "\n",
        "def onehotencoder(seq, nt_num):\n",
        "    '''Convert to single and di-nucleotide hotencode. Adapted from Lindel'''\n",
        "    seq = str(seq).upper()\n",
        "    nt = ['A','C','G','T']\n",
        "    head = []\n",
        "    l = len(seq)\n",
        "    # All nucleotide options per position (A0,C0,G0,T0,A1,C1,G1,T1...):\n",
        "    # In the case of single nucleotide encoding\n",
        "    if nt_num == 1:\n",
        "        for k in range(l):\n",
        "            for i in range(4):\n",
        "                head.append(nt[i]+str(k))\n",
        "    # For dinucleotides\n",
        "    elif nt_num == 2:\n",
        "        for k in range(l-1):\n",
        "            for i in range(4):\n",
        "                for j in range(4):\n",
        "                    head.append(nt[i]+nt[j]+str(k))\n",
        "    # For trinucleotides\n",
        "    elif nt_num == 3:\n",
        "        for k in range(l-2):\n",
        "            for i in range(4):\n",
        "                for j in range(4):\n",
        "                    for h in range(4):\n",
        "                        head.append(nt[i]+nt[j]+nt[h]+str(k))\n",
        "    # Encoding\n",
        "    head_idx = {}\n",
        "    for idx, key in enumerate(head):\n",
        "        # Dictionary of classes per position 0:A0, 1:C0\n",
        "        head_idx[key] = idx\n",
        "    # Initialize numpy array of seq_len*4 for single nt or seq_len-1*4*4 for di-nucleotides\n",
        "    encode = np.zeros(len(head_idx))\n",
        "    # Encode\n",
        "    if nt_num == 1:\n",
        "        for j in range(l):\n",
        "            # nt in the sequence + position in the sequence to get the dictionary key o codified nts\n",
        "            encode[head_idx[seq[j]+str(j)]] = 1.\n",
        "    elif nt_num == 2:\n",
        "        # For dints the last nt will be alone\n",
        "        for k in range(l-1):\n",
        "            encode[head_idx[seq[k:k+2]+str(k)]] = 1.\n",
        "    elif nt_num == 3:\n",
        "        # For dints the last nt will be alone\n",
        "        for m in range(l-2):\n",
        "            encode[head_idx[seq[m:m+3]+str(m)]] = 1.\n",
        "    return(encode, head)\n",
        "\n",
        "\n",
        "def seq_pattern_count(seq, nts):\n",
        "    \"\"\"Count the numper of each di-, tri-, ..., nucleotide.\n",
        "        Position independent combinations of nucleotides \"\"\"\n",
        "    tri_nts = product('ACGT', repeat=nts)\n",
        "    count_arr = list()\n",
        "    header = list()\n",
        "    for i,j in enumerate(tri_nts):\n",
        "        tnt = ''.join(j)\n",
        "        header.append(tnt)\n",
        "        count_arr.append(seq.count(tnt))\n",
        "    return (count_arr, header)\n",
        "\n",
        "\n",
        "def GCcontent(seq):\n",
        "    ''' Percent of GC in a given sequence'''\n",
        "    seq = str(seq).upper()\n",
        "    percent = ((seq.count('G')+seq.count('C'))/len(seq))*100\n",
        "    return percent\n",
        "\n",
        "\n",
        "def homopolymer(seq):\n",
        "    \"\"\" 1 for sequences with homopolymers. At least 4 nts\"\"\"\n",
        "    seq = str(seq).upper()\n",
        "    nt = ['A', 'C', 'G', 'T']\n",
        "    encode = np.zeros(len(nt))\n",
        "    for i in range(0, len(nt)):\n",
        "        if nt[i]*4 in seq:\n",
        "            encode[i] = 1.\n",
        "    return (encode, nt)\n",
        "\n",
        "#### RNA/DNA hybriditzation Tm ((From biopython)\n",
        "# Sugimoto et al. (1995), Biochemistry 34: 11211-11216\n",
        "#\n",
        "#R_DNA_NN1 = {\n",
        "#\"init\": (1.9, -3.9), \"init_A/T\": (0, 0), \"init_G/C\": (0, 0),\n",
        "#\"init_oneG/C\": (0, 0), \"init_allA/T\": (0, 0), \"init_5T/A\": (0, 0),\n",
        "#\"sym\": (0, 0),\n",
        "#\"AA/TT\": (-11.5, -36.4), \"AC/TG\": (-7.8, -21.6), \"AG/TC\": (-7.0, -19.7),\n",
        "#\"AT/TA\": (-8.3, -23.9), \"CA/GT\": (-10.4, -28.4), \"CC/GG\": (-12.8, -31.9),\n",
        "#\"CG/GC\": (-16.3, -47.1), \"CT/GA\": (-9.1, -23.5), \"GA/CT\": (-8.6, -22.9),\n",
        "#\"GC/CG\": (-8.0, -17.1), \"GG/CC\": (-9.3, -23.2), \"GT/CA\": (-5.9, -12.3),\n",
        "#\"TA/AT\": (-7.8, -23.2), \"TC/AG\": (-5.5, -13.5), \"TG/AC\": (-9.0, -26.1),\n",
        "#\"TT/AA\": (-7.8, -21.9)}\n",
        "\n",
        "#### RNA folding energy --> sapacer or spacer+scaffold\n",
        "# Cluster installed version of mfold web application has been used to precompute the free energy of the most\n",
        "# probable secundary structure\n",
        "# M. Zuker\n",
        "# Mfold web server for nucleic acid folding and hybridization prediction.\n",
        "# Nucleic Acids Res. 31 (13), 3406-15, (2003)\n",
        "\n",
        "\n",
        "\n",
        "#############\n",
        "## Base editing specific sequence features\n",
        "#############\n",
        "def editable(seq, base):\n",
        "    seq = str(seq).upper()\n",
        "    base = base.upper()\n",
        "    encode = np.zeros(len(seq))\n",
        "    for pos,i in enumerate(seq):\n",
        "        if i == base:\n",
        "            encode[pos] = 1.\n",
        "    return encode\n",
        "\n",
        "\n",
        "#############\n",
        "## DBS repair specific sequence features\n",
        "#############\n",
        "def microhomology(seq, cut_site=30):\n",
        "    '''\n",
        "    Adapted from Sangsu Bae, 2014 (Microhomology-based choice of Cas9 nuclease target sites)\n",
        "\n",
        "    This function allows the calculation of the microhomology score. It takes into account the distance and the length of\n",
        "    the sequence homology.\n",
        "    '''\n",
        "    # Capitalize and use as a string the sequence:\n",
        "    seq = str(seq).upper()\n",
        "    # Length weight\n",
        "    length_weight = 20.0\n",
        "    # Cut sides length\n",
        "    left = cut_site  # Insert the position expected to be broken.\n",
        "    right = len(seq) - int(left)\n",
        "    # variable declaration\n",
        "    k = int()  # sequence size to be used for checking homology\n",
        "    i = int()  # start position of sequence substraction at the left side of the cut\n",
        "    j = int()  # start position of sequence substraction at the right side of the cut\n",
        "\n",
        "    ### PARSING SEQUENCE IN RESEARCH OF MICROHOMOLOGY SEQUENCES BETWEEN BOTH SIDES OF THE CUT ###\n",
        "    microhomo = list()\n",
        "    for k in range(2, left)[::-1]:  # From length to 2, 1 by 1. So, from bigger homological segments to smaller\n",
        "        for j in range(left, left + right - k + 1):\n",
        "            for i in range(0, left - k + 1):\n",
        "                # comparing pice of left side of the cut sequence with a pice of the right side of the cut\n",
        "                if seq[i:i + k] == seq[j:j + k]:\n",
        "                    delLen = j - i  # deletion length\n",
        "                    # Homology sequence, start and end points for both sides and deletion size are saved in a list of lists\n",
        "                    microhomo.append([seq[i:i + k], i, i + k, j, j + k, delLen])\n",
        "\n",
        "                    ### REMOVING DUPLICATIONS ###\n",
        "    # After searching out all microhomology patterns, duplication should be removed!!\n",
        "    trimed = list()\n",
        "\n",
        "    # Check if there is content in the list and inisialize the counters\n",
        "    if len(microhomo) != 0:\n",
        "        sum_score_3 = 0\n",
        "        sum_score_not_3 = 0\n",
        "        scoreSummary = list()\n",
        "\n",
        "        # Access to the info (6 fields) inside each one of the hits\n",
        "        for i in range(len(microhomo)):\n",
        "            n = 0\n",
        "            score_3 = 0\n",
        "            score_not_3 = 0\n",
        "\n",
        "            left_start = microhomo[i][1]\n",
        "            left_end = microhomo[i][2]\n",
        "            right_start = microhomo[i][3]\n",
        "            right_end = microhomo[i][4]\n",
        "\n",
        "            # Access to the info again to compare. In the first case there is no reference, but in the second case\n",
        "            # the first will be retrived, and in the third case the first and the second will be used as references.\n",
        "            for j in range(i):\n",
        "\n",
        "                left_start_ref = microhomo[j][1]\n",
        "                left_end_ref = microhomo[j][2]\n",
        "                right_start_ref = microhomo[j][3]\n",
        "                right_end_ref = microhomo[j][4]\n",
        "\n",
        "                # Each homoloy pattern is comparet with those bigger. If it is inside a bigger one in both sides,\n",
        "                #  it will not be token into account\n",
        "                if (left_start >= left_start_ref) and (left_end <= left_end_ref) and (\n",
        "                            right_start >= right_start_ref) and (right_end <= right_end_ref):\n",
        "                    if (left_start - left_start_ref) == (right_start - right_start_ref) and (\n",
        "                                left_end - left_end_ref) == (right_end - right_end_ref):\n",
        "                        n += 1\n",
        "                        break\n",
        "                else:\n",
        "                    pass\n",
        "\n",
        "                    # From all hits duplicated, the bigger one is the one saved\n",
        "            if n == 0:\n",
        "\n",
        "                # Save all the info of the trimed microhomology events\n",
        "                trimed.append(microhomo[i])\n",
        "\n",
        "                # Let's calculate the score!!\n",
        "                length = microhomo[i][5]\n",
        "                pattern = microhomo[i][0]\n",
        "\n",
        "                length_factor = round(1 / exp((length) / (length_weight)), 3)\n",
        "                num_GC = len(findall('G', pattern)) + len(findall('C', pattern))\n",
        "                score = 100 * length_factor * ((len(pattern) - num_GC) + (num_GC * 2))\n",
        "\n",
        "                # This gives the image of how the outcome will looks like, the pattern that is homologous, length of the deletion,\n",
        "                # score of the microhomology deletion and start point of the delation.\n",
        "                scoreSummary.append([seq[0:left_end] + '-' * length + seq[right_end:], pattern, length, round(score, 1),\n",
        "                                     len(seq[0:left_end])])\n",
        "\n",
        "                # Sum score in different counters in function of out or in frame deletion\n",
        "                if (length % 3) == 0:\n",
        "                    sum_score_3 += score\n",
        "                else:\n",
        "                    sum_score_not_3 += score\n",
        "\n",
        "        microhom_score = sum_score_3 + sum_score_not_3\n",
        "        # outFrame_score = (sum_score_not_3)*100/(sum_score_3+sum_score_not_3)\n",
        "\n",
        "        return (scoreSummary, round(microhom_score, 1))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    #######\n",
        "    ## Load sequences to compute the features\n",
        "    #######\n",
        "    #data_path = './Data/Library/'\n",
        "    #Spacer + PAM\n",
        "    #fasta_gRNAsequences = data_path+'./C3H_gRNAs.fasta'\n",
        "    #fasta_gRNAsequences = data_path+'./C3H_targets.csv'\n",
        "    fasta_gRNAsequences = './C3H_targets.csv'\n",
        "    ### Explored range of the sequence\n",
        "    #ini = 0\n",
        "    #end = 20\n",
        "    cutsite = 60\n",
        "    ini = cutsite - 17\n",
        "    end = cutsite + 3\n",
        "\n",
        "    # Import sequences as pd data.frame\n",
        "    target_seqs_data = read_target_seqs(fasta_gRNAsequences)\n",
        "\n",
        "    ######\n",
        "    ### Lists of features to get (this is the list of general features that can be used for any strategy)\n",
        "    ######\n",
        "    ids = list()\n",
        "    ntdtrt = list() # Nucleotides, dinucleotides and trinucleotides per position one hot encoded\n",
        "    GC_content = list()\n",
        "    nucleotides_count = list()\n",
        "    #dinucleotides_count = list()\n",
        "    #trinucleotides_count = list()\n",
        "    #homopolymer_list = list()\n",
        "    #hybriditzations = list()\n",
        "    #hybriditzations_seed = list()\n",
        "    #secundary_structures = list()\n",
        "    #secundary_structures_spacer = list()\n",
        "\n",
        "    # ######\n",
        "    # ### Load pre-computed features (secundary structures)\n",
        "    # ######\n",
        "    # # Dictionary with free energy of secundary structures\n",
        "    # features_path = './Data/Features/'\n",
        "    # mfold_path = features_path+'freeEnergy_spacer-scaffold.csv'\n",
        "    # fold_dict = dict()\n",
        "    # with open(mfold_path) as csv_file:\n",
        "    #     csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    #     for row in csv_reader:\n",
        "    #         fold_dict[row[0]] = row[1]\n",
        "    # # The same but for just the spacer\n",
        "    # mfold_spacer_path = features_path+'./freeEnergy_spacer.csv'\n",
        "    # fold_spacer_dict = dict()\n",
        "    # with open(mfold_spacer_path) as csv_file:\n",
        "    #     csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    #     for row in csv_reader:\n",
        "    #         fold_spacer_dict[row[0]] = row[1]\n",
        "    #\n",
        "    #######\n",
        "    ### Calculate general features\n",
        "    #######\n",
        "    # if starting with a FASTA list of targets\n",
        "    #for record in SeqIO.parse(fasta_gRNAsequences,'fasta'):\n",
        "    # if starting with the data.frame file\n",
        "    for seq_id, seq_nt in target_seqs_data.iterrows():\n",
        "        # Ids\n",
        "        ids.append(seq_nt[\"gRNA_id\"])\n",
        "        # Nucleotidic, dinucleotidic and trinucleotidic one hot encoded sequences\n",
        "        gRNA_nt_hotencode = onehotencoder(seq_nt[\"target_seq\"][ini:end], 1)[0]\n",
        "        gRNA_dint_hotencode = onehotencoder(seq_nt[\"target_seq\"][ini:end], 2)[0]\n",
        "        #gRNA_trint_hotencode = onehotencoder(record.seq[ini:end], 3)[0]\n",
        "        #ntdtrt_encoded = np.concatenate((gRNA_nt_hotencode, gRNA_dint_hotencode, gRNA_trint_hotencode))\n",
        "        ntdtrt_encoded = np.concatenate((gRNA_nt_hotencode, gRNA_dint_hotencode))\n",
        "        ntdtrt.append(ntdtrt_encoded)\n",
        "        # Nucleotide, dinucleotide and trinucleotide count independent to the position\n",
        "        nts = seq_pattern_count(seq_nt[\"target_seq\"][ini:end], 1)[0]\n",
        "        nucleotides_count.append(nts)\n",
        "        dints = seq_pattern_count(seq_nt[\"target_seq\"][ini:end], 2)[0]\n",
        "        #dinucleotides_count.append(dints)\n",
        "    #     trints = seq_pattern_count(record.seq[ini:end], 3)[0]\n",
        "    #     trinucleotides_count.append(trints)\n",
        "    #     # Homopolymers (min 4nt)\n",
        "    #     homop = homopolymer(record.seq[ini:end])[0]\n",
        "    #     homopolymer_list.append(homop)\n",
        "        # GC content\n",
        "        GC_content.append(GCcontent(seq_nt[\"target_seq\"][ini:end]))\n",
        "    #     # Hibriditzation\n",
        "    #     tm = mt.Tm_NN(record.seq[ini:end], nn_table=mt.R_DNA_NN1)\n",
        "    #     hybriditzations.append(tm)\n",
        "    #     tm_seed = mt.Tm_NN(record.seq[10:20], nn_table=mt.R_DNA_NN1)\n",
        "    #     hybriditzations_seed.append(tm_seed)\n",
        "    #     # Secundary structures\n",
        "    #     secundary_structures.append(fold_dict[record.id])\n",
        "    #     secundary_structures_spacer.append(fold_spacer_dict[record.id])\n",
        "    #     # Editability\n",
        "    #     #gRNA_editable_C = editable(record.seq[0:20], 'C')\n",
        "    #     #gRNA_editable_A = editable(record.seq[0:20], 'A')\n",
        "\n",
        "    # Headers to identify sequence features\n",
        "    nt_head = onehotencoder(target_seqs_data.iloc[0,1][ini:end],1)[1]\n",
        "    dnt_head = onehotencoder(target_seqs_data.iloc[0,1][ini:end],2)[1]\n",
        "    # trint_head = onehotencoder(record.seq[ini:end],3)[1]\n",
        "    # homo_nts = homopolymer(record.seq[ini:end])[1]\n",
        "    # homopolymer_head = ['poly_' + s for s in homo_nts]\n",
        "    nt_count_head = seq_pattern_count(target_seqs_data.iloc[0,1][ini:end],1)[1]\n",
        "    dint_count_head = seq_pattern_count(target_seqs_data.iloc[0,1][ini:end],2)[1]\n",
        "    # trint_count_head = seq_pattern_count(record.seq[ini:end],3)[1]\n",
        "\n",
        "    #######\n",
        "    ### Calculate MMEJ features\n",
        "    #######\n",
        "    #MH_fasta = './C3H_cutSite_70.fa'\n",
        "    #for record in SeqIO.parse(MH_fasta,'fasta'):\n",
        "    #    possible_MH = microhomology(record.seq, 35) #Tpple:\n",
        "        # 0 --> MHs [seq_result, patttern, del_length, MH_score and del_start\n",
        "        # 1 --> total MH score (sum of all possibl MH deletions\n",
        "\n",
        "\n",
        "    ########\n",
        "    ### Generate matrix and file with all selected features\n",
        "    ########\n",
        "    ### Data frame with all together (1612x396): features and ids\n",
        "    df0 = pd.DataFrame(ids, columns=['ids'])\n",
        "    # df1 = pd.DataFrame(np.row_stack(ntdtrt), columns=nt_head+dnt_head+trint_head)\n",
        "    df1 = pd.DataFrame(np.row_stack(ntdtrt), columns=nt_head + dnt_head)\n",
        "    df2 = pd.DataFrame(np.row_stack(nucleotides_count), columns=nt_count_head)\n",
        "    #df3 = pd.DataFrame(np.row_stack(dinucleotides_count), columns=dint_count_head)\n",
        "    #df4 = pd.DataFrame(np.row_stack(trinucleotides_count), columns=trint_count_head)\n",
        "    #df5 = pd.DataFrame(np.row_stack(homopolymer_list), columns=homopolymer_head)\n",
        "    df = pd.concat([df0, df1, df2], axis=1, sort=False)\n",
        "    #df = pd.concat([df0, df1, df2, df3, df4, df5], axis=1, sort=False)\n",
        "    df['GC_content'] = GC_content\n",
        "    #df['hybriditzation'] = hybriditzations\n",
        "    #df['hybriditzation_seed'] = hybriditzations_seed\n",
        "    #df['sec_structure'] = secundary_structures\n",
        "    #df['sec_structure_spacer'] = secundary_structures_spacer\n",
        "    print(df.shape)\n",
        "\n",
        "    # csv\n",
        "    out_csv = './gRNA_features.csv'\n",
        "    df.to_csv(out_csv, sep=',', index=False)\n",
        "\n",
        "\n",
        "    ##### DATA\n",
        "    # Files: gRNA coordinates, gRNAs sequences, extended gRNA sequences (mm10 and C3H)\n",
        "    # From gRNA coordinates to bed with cut site in the midel and n arm length + from bed to fasta (to extend sequences)\n",
        "    ##### FEATURES\n",
        "    # Nucleotides, dinucleotides, trinucleotides (one hot encode)\n",
        "    # Nucleotides, dinucleotides, trinucleotides count\n",
        "    # Homopolymer by nt\n",
        "    # GC content\n",
        "    # RNA/DNA hybriditzation (tm) [whole spacer or seed]\n",
        "    # Secundary structures (mfold) [spacer or spacer+scaffold]\n",
        "    ##### FEATURES (specifics for a certain strategy)\n",
        "    # MH patterns\n",
        "    # Editability\n",
        "    ##### Metadata: DNasaI (chromatin), histone modifications...\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}